{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric values found in the data:\n",
      "             date measurement  hour value\n",
      "0      2022-01-01    AMB_TEMP     0  13.5\n",
      "1      2022-01-01          CO     0  0.21\n",
      "2      2022-01-01          NO     0   0.4\n",
      "3      2022-01-01         NO2     0   6.8\n",
      "4      2022-01-01         NOx     0   7.3\n",
      "...           ...         ...   ...   ...\n",
      "131755 2037-01-02         SO2    23   0.6\n",
      "131756 2037-01-03       WD_HR    23    60\n",
      "131757 2037-01-04  WIND_DIREC    23    52\n",
      "131758 2037-01-05  WIND_SPEED    23   2.1\n",
      "131759 2037-01-06       WS_HR    23   2.1\n",
      "\n",
      "[131400 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_2292\\1421580982.py:74: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  numerical_data['value'].fillna(0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image,UnidentifiedImageError\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, numerical_data, image_data_folder, transform=None):\n",
    "        self.numerical_data = numerical_data\n",
    "        self.image_data_folder = image_data_folder\n",
    "        self.transform = transform\n",
    "        self.image_data = self._load_image_data()\n",
    "\n",
    "    def _load_image_data(self):\n",
    "        image_data = {}\n",
    "        for root, dirs, files in os.walk(self.image_data_folder):\n",
    "            for dir_name in dirs:\n",
    "                date_str = dir_name\n",
    "                image_data[date_str] = {}\n",
    "                dir_path = os.path.join(root, dir_name)\n",
    "                for hour in range(24):\n",
    "                    img_path = os.path.join(dir_path, f\"009-{date_str}{hour:02d}00.jpg\")\n",
    "                    try:\n",
    "                        if os.path.exists(img_path):\n",
    "                            image_data[date_str][hour] = img_path\n",
    "                        else:\n",
    "                            image_data[date_str][hour] = None\n",
    "                    except(OSError,UnidentifiedImageError):\n",
    "                        image_data[date_str][hour] = None\n",
    "        return image_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numerical_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.numerical_data.iloc[idx]\n",
    "        date = row['date'].strftime('%Y%m%d')\n",
    "        hour = row['hour']\n",
    "        numerical_features = row.drop(['date', 'hour']).values.astype(np.float32)\n",
    "        \n",
    "        img_path = self.image_data[date][hour]\n",
    "        if img_path:\n",
    "            img = Image.open(img_path)\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "        else:\n",
    "            img = torch.zeros(3, 224, 224)  # Handle missing images\n",
    "        \n",
    "        return numerical_features, img, row['value']  # Assuming the target is the value for that hour\n",
    "\n",
    "# Preprocess numerical data\n",
    "numerical_data = pd.read_csv('./dataset/Linkou_2022.csv')\n",
    "#drop the Stations column\n",
    "numerical_data = numerical_data.drop(columns=['Station'])\n",
    "numerical_data['date'] = pd.to_datetime(numerical_data['date'],format=\"%d-%m-%Y %H:%M\",dayfirst=True)\n",
    "numerical_data = numerical_data.melt(id_vars=['date', 'measurement'], var_name='hour', value_name='value')\n",
    "numerical_data['hour'] = numerical_data['hour'].astype(int)\n",
    "\n",
    "#clean the data\n",
    "# Check for non-numeric values in 'value' column\n",
    "non_numeric_values = numerical_data[~numerical_data['value'].apply(lambda x: np.issubdtype(type(x), np.number))]\n",
    "\n",
    "# Print non-numeric values for debugging\n",
    "print(\"Non-numeric values found in the data:\")\n",
    "print(non_numeric_values)\n",
    "\n",
    "# Convert 'value' column to numeric, coercing errors\n",
    "numerical_data['value'] = pd.to_numeric(numerical_data['value'], errors='coerce')\n",
    "\n",
    "# Handle missing values if any (e.g., fill with zero or drop)\n",
    "numerical_data['value'].fillna(0, inplace=True)\n",
    "\n",
    "#Pivot the table\n",
    "numerical_data = numerical_data.pivot_table(index=['date', 'hour'], columns='measurement', values='value').reset_index()\n",
    "\n",
    "# Normalize numerical data\n",
    "scaler = StandardScaler()\n",
    "numerical_data.iloc[:, 2:] = scaler.fit_transform(numerical_data.iloc[:, 2:])\n",
    "\n",
    "# Image preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create Dataset and DataLoader\n",
    "image_data_folder = './dataset/009_Linkou'\n",
    "# sequence_length = 24\n",
    "dataset = MultimodalDataset(numerical_data, image_data_folder, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "# Define CNN model\n",
    "class ImageCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ImageCNN, self).__init__()\n",
    "        self.cnn = torchvision.models.resnet50(pretrained=True)\n",
    "        self.cnn = nn.Sequential(*list(self.cnn.children())[:-1])\n",
    "        self.fc = nn.Linear(2048, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Define LSTM model for numerical data\n",
    "class NumericalLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(NumericalLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(x.device)\n",
    "        c_0 = torch.zeros(num_layers, x.size(0), hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h_0, c_0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Combine CNN and LSTM outputs\n",
    "class MultimodalNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(MultimodalNet, self).__init__()\n",
    "        self.image_cnn = ImageCNN()\n",
    "        self.numerical_lstm = NumericalLSTM(input_size, hidden_size, num_layers)\n",
    "        self.fc1_combined = nn.Linear(256, 64)\n",
    "        self.fc2_combined = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, num_data, img_data):\n",
    "        img_features = self.image_cnn(img_data)\n",
    "        num_features = self.numerical_lstm(num_data)\n",
    "        combined_features = torch.cat((num_features, img_features), dim=1)\n",
    "        x = torch.relu(self.fc1_combined(combined_features))\n",
    "        x = self.fc2_combined(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\envs\\teep_test1\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\LENOVO\\anaconda3\\envs\\teep_test1\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Model set to training mode\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "input_size = 15  # Number of numerical features\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Instantiate model, loss function, and optimizer\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultimodalNet(input_size, hidden_size, num_layers).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"Epoch: \",epoch+1)\n",
    "    model.train()\n",
    "    print(\"Model set to training mode\")\n",
    "    running_loss = 0.0\n",
    "    i=0\n",
    "    for num_features, img_features, targets in dataloader:\n",
    "        print(f\"Batch: {i+1}\")\n",
    "        num_features, img_features, targets = num_features.to(device), img_features.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(num_features.unsqueeze(1), img_features)\n",
    "        loss = criterion(outputs.squeeze(), targets.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        i+=1\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teep_test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
