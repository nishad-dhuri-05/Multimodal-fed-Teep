{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def to_float_with_nan(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return -1.0\n",
    "\n",
    "vectorized_to_float_with_nan = np.vectorize(to_float_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image,UnidentifiedImageError\n",
    "import os\n",
    "import glob\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "# Mock function to simulate loading data from files\n",
    "def load_images_for_date(date, image_folder):\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    images = []\n",
    "    for hour in range(24):\n",
    "        pattern=os.path.join(image_folder,date_str,f\"???-{date_str}{hour:02d}00.jpg\")\n",
    "        matched_files=glob.glob(pattern)\n",
    "        if matched_files:\n",
    "            img_path=matched_files[0]\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    images.append(img.copy())\n",
    "            except(OSError,UnidentifiedImageError):\n",
    "                images.append(None)\n",
    "        else:\n",
    "            images.append(None)\n",
    "    return images\n",
    "\n",
    "def resize_image(images):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to 224x224 directly\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    features=[]\n",
    "    for img in images:\n",
    "        if img is not None:\n",
    "            img=transform(img)\n",
    "            features.append(img)\n",
    "        else:\n",
    "            features.append(torch.zeros(3,224,224))\n",
    "    return features\n",
    "\n",
    "def load_data_for_segment(station_name, start_date, end_date):\n",
    "    print(f'Loading data for {station_name} from {start_date} to {end_date}')\n",
    "    num_data=pd.read_csv(f'./dataset/{station_name}.csv')\n",
    "    #process the numerical data\n",
    "    num_data=num_data.drop(columns=['Station'])\n",
    "    num_data['date']=pd.to_datetime(num_data['date'],format=\"%d-%m-%Y %H:%M\",dayfirst=True)\n",
    "    #delete all entries that are not in the segment\n",
    "    print(num_data.head(50))\n",
    "    num_data=num_data[(num_data['date']>=start_date) & (num_data['date']<end_date)]\n",
    "    print(\"Loaded num data!!!\")\n",
    "    #preprocess the data appropriately\n",
    "    img_data={date:load_images_for_date(date,f'./dataset/{station_name}') for date in num_data['date'].dt.date.unique()}\n",
    "    print(\"Loaded image data!!!\")\n",
    "    #process the image data, ie. apply transformation\n",
    "    image_features = {date: resize_image(images) for date, images in img_data.items()}\n",
    "    print(\"Resized image data!!!\")\n",
    "    del img_data\n",
    "    #reshape the num data\n",
    "    num_data = num_data.melt(id_vars=['date', 'measurement'], var_name='hour', value_name='value')\n",
    "    num_data['hour'] = num_data['hour'].astype(int)\n",
    "    num_data=num_data.pivot(index=['date','hour'],columns='measurement',values='value').reset_index()\n",
    "    # num_data['date']=num_data['date'].dt.month\n",
    "    num_data['month']=num_data['date'].dt.month\n",
    "    print(\"Processed num data!!!\")\n",
    "    #generate combined features\n",
    "    combined_features = []\n",
    "    targets = []\n",
    "    #instead of each row, we take 18 rows at a time\n",
    "    for idx, row in num_data.iterrows():\n",
    "        # print(row)\n",
    "        date = row['date'].date()\n",
    "        # print(date)\n",
    "        hour = row['hour']\n",
    "        numerical_features = row.drop(['date']).values\n",
    "        # print(hour)\n",
    "        # print(numerical_features)\n",
    "        # print(image_features[date][23])\n",
    "        img_features = image_features[date][hour]\n",
    "        # print(img_features.shape)\n",
    "        #flatten this thing\n",
    "        img_features = img_features.view(-1)\n",
    "        #convert to numpy array\n",
    "        img_features = img_features.detach().numpy()\n",
    "        print(img_features.shape)\n",
    "        img_features = img_features.reshape(-1)\n",
    "        print(numerical_features.shape)\n",
    "        numerical_features=numerical_features.reshape(-1)\n",
    "        # print(img_features)\n",
    "        # print(numerical_features)\n",
    "        #we can consider adding latitute and longitude as well to the input features\n",
    "        # numerical_features=np.array(numerical_features).reshape(1,-1)\n",
    "        # combined_feature=\n",
    "        # combined_feature=np.array()\n",
    "        combined_feature = np.concatenate((numerical_features, img_features),axis=None)\n",
    "        combined_features.append(combined_feature)\n",
    "        # targets.append(row['value'])  # Assuming the target is the value for that hour\n",
    "        targets.append(row.drop(['date','hour','month']).values)  # Assuming the target is the value for that hour\n",
    "    print(\"Generated combined features and targets!!!\")\n",
    "    combined_features = np.array(combined_features)\n",
    "    targets = np.array(targets)\n",
    "    # print(combined_features)\n",
    "    # print(targets)\n",
    "    return combined_features, targets\n",
    "\n",
    "class LargeDatasetSegmentLoader(Dataset):\n",
    "    def __init__(self, station_ids, segment_duration):\n",
    "        self.station_ids = station_ids\n",
    "        self.segment_duration = segment_duration\n",
    "        self.current_station_index = 0\n",
    "        self.current_segment_start = None\n",
    "        self.current_segment_end = None\n",
    "        self.features = None\n",
    "        self.targets = None\n",
    "        self.load_next_segment()\n",
    "\n",
    "    def load_next_segment(self):\n",
    "        if self.current_station_index >= len(self.station_ids):\n",
    "            self.features = None\n",
    "            self.targets = None\n",
    "            return\n",
    "        \n",
    "        station_id = self.station_ids[self.current_station_index]\n",
    "        if self.current_segment_start is None:\n",
    "            self.current_segment_start = pd.to_datetime('2022-01-01')\n",
    "        \n",
    "        self.current_segment_end = self.current_segment_start + self.segment_duration\n",
    "        if self.current_segment_end > pd.to_datetime('2022-12-31'):\n",
    "            self.current_segment_end = pd.to_datetime('2022-12-31')\n",
    "        \n",
    "        self.features, self.targets = load_data_for_segment(\n",
    "            station_id, self.current_segment_start, self.current_segment_end\n",
    "        )\n",
    "        \n",
    "        self.current_segment_start = self.current_segment_end\n",
    "        if self.current_segment_start >= pd.to_datetime('2022-12-31'):\n",
    "            self.current_station_index += 1\n",
    "            self.current_segment_start = None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features) if self.features is not None else 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.features):\n",
    "            self.load_next_segment()\n",
    "            idx = 0  # Reset index after loading new segment\n",
    "        self.features[idx] = vectorized_to_float_with_nan(self.features[idx])\n",
    "        self.targets[idx] = vectorized_to_float_with_nan(self.targets[idx])\n",
    "        self.features[idx]=self.features[idx].astype(np.float32)\n",
    "        self.targets[idx]=self.targets[idx].astype(np.float32)\n",
    "        print(self.features[idx].shape)\n",
    "        print(self.features[idx])\n",
    "        for e in self.features[idx]:\n",
    "            print(e)\n",
    "        #some of the values are not floating point, so we need to convert them to float\n",
    "        feature = torch.tensor(self.features[idx],dtype=torch.float32)\n",
    "        target = torch.tensor(self.targets[idx],dtype=torch.float32)\n",
    "        return feature, target\n",
    "        # Separate numerical and image features\n",
    "        num_features = torch.tensor(feature[:20], dtype=torch.float32).unsqueeze(1)  # First 20 features\n",
    "        img_features = torch.tensor(feature[20:], dtype=torch.float32).reshape(3, 224, 224)  # Rest are image features\n",
    "        target = torch.tensor(target, dtype=torch.float32)\n",
    "        \n",
    "        return num_features, img_features, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import os\n",
    "import glob\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "def load_images_for_date(date, image_folder):\n",
    "    date_str = date.strftime('%Y%m%d')\n",
    "    images = []\n",
    "    for hour in range(24):\n",
    "        pattern = os.path.join(image_folder, date_str, f\"???-{date_str}{hour:02d}00.jpg\")\n",
    "        matched_files = glob.glob(pattern)\n",
    "        if matched_files:\n",
    "            img_path = matched_files[0]\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    images.append(img.copy())\n",
    "            except (OSError, UnidentifiedImageError):\n",
    "                images.append(None)\n",
    "        else:\n",
    "            images.append(None)\n",
    "    return images\n",
    "\n",
    "def resize_image(images):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize images to 224x224 directly\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    features = []\n",
    "    for img in images:\n",
    "        if img is not None:\n",
    "            img = transform(img)\n",
    "            features.append(img)\n",
    "        else:\n",
    "            features.append(torch.zeros(3, 224, 224))\n",
    "    return features\n",
    "\n",
    "def load_data_for_segment(station_name, start_date, end_date):\n",
    "    print(f'Loading data for {station_name} from {start_date} to {end_date}')\n",
    "    num_data = pd.read_csv(f'./dataset/{station_name}.csv')\n",
    "    num_data = num_data.drop(columns=['Station'])\n",
    "    num_data['date'] = pd.to_datetime(num_data['date'], format=\"%d-%m-%Y %H:%M\", dayfirst=True)\n",
    "    # print(num_data.head(50))\n",
    "    num_data = num_data[(num_data['date'] >= start_date) & (num_data['date'] < end_date)]\n",
    "    print(\"Loaded num data!!!\")\n",
    "    img_data = {date: load_images_for_date(date, f'./dataset/{station_name}') for date in num_data['date'].dt.date.unique()}\n",
    "    print(\"Loaded image data!!!\")\n",
    "    image_features = {date: resize_image(images) for date, images in img_data.items()}\n",
    "    print(\"Resized image data!!!\")\n",
    "    del img_data\n",
    "    num_data = num_data.melt(id_vars=['date', 'measurement'], var_name='hour', value_name='value')\n",
    "    num_data['hour'] = num_data['hour'].astype(int)\n",
    "    num_data = num_data.pivot(index=['date', 'hour'], columns='measurement', values='value').reset_index()\n",
    "    num_data['month'] = num_data['date'].dt.month\n",
    "    print(\"Processed num data!!!\")\n",
    "    combined_features = []\n",
    "    targets = []\n",
    "\n",
    "    for idx, row in num_data.iterrows():\n",
    "        date = row['date'].date()\n",
    "        hour = row['hour']\n",
    "        numerical_features = row.drop(['date']).values\n",
    "\n",
    "        # Convert numerical features to float and handle non-numeric values\n",
    "        numerical_features = pd.to_numeric(numerical_features, errors='coerce').astype(float)\n",
    "        \n",
    "        img_features = image_features[date][hour]\n",
    "        img_features = img_features.view(-1)\n",
    "        img_features = img_features.numpy()\n",
    "\n",
    "        combined_feature = np.concatenate((numerical_features, img_features), axis=None)\n",
    "        combined_features.append(combined_feature)\n",
    "        targets.append(row.drop(['date', 'hour', 'month']).values)\n",
    "        \n",
    "    print(\"Generated combined features and targets!!!\")\n",
    "    combined_features = np.array(combined_features)\n",
    "    targets = np.array(targets)\n",
    "    combined_feature=vectorized_to_float_with_nan(combined_features)\n",
    "    targets=vectorized_to_float_with_nan(targets)\n",
    "    \n",
    "    return combined_features, targets\n",
    "\n",
    "class LargeDatasetSegmentLoader(Dataset):\n",
    "    def __init__(self, station_ids, segment_duration):\n",
    "        self.station_ids = station_ids\n",
    "        self.segment_duration = segment_duration\n",
    "        self.current_station_index = 0\n",
    "        self.current_segment_start = None\n",
    "        self.current_segment_end = None\n",
    "        self.features = None\n",
    "        self.targets = None\n",
    "        self.load_next_segment()\n",
    "\n",
    "    def load_next_segment(self):\n",
    "        if self.current_station_index >= len(self.station_ids):\n",
    "            self.features = None\n",
    "            self.targets = None\n",
    "            return\n",
    "        \n",
    "        station_id = self.station_ids[self.current_station_index]\n",
    "        if self.current_segment_start is None:\n",
    "            self.current_segment_start = pd.to_datetime('2022-01-01')\n",
    "        \n",
    "        self.current_segment_end = self.current_segment_start + self.segment_duration\n",
    "        if self.current_segment_end > pd.to_datetime('2022-12-31'):\n",
    "            self.current_segment_end = pd.to_datetime('2022-12-31')\n",
    "        \n",
    "        self.features, self.targets = load_data_for_segment(\n",
    "            station_id, self.current_segment_start, self.current_segment_end\n",
    "        )\n",
    "        \n",
    "        self.current_segment_start = self.current_segment_end\n",
    "        if self.current_segment_start >= pd.to_datetime('2022-12-31'):\n",
    "            self.current_station_index += 1\n",
    "            self.current_segment_start = None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features) if self.features is not None else 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx >= len(self.features):\n",
    "            self.load_next_segment()\n",
    "            idx = 0  # Reset index after loading new segment\n",
    "\n",
    "        feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        return feature, target\n",
    "\n",
    "# Example usage\n",
    "station_ids = ['Keelung', 'Chiayi', 'Tucheng','Banqiao']  # Replace with actual station IDs\n",
    "segment_duration = pd.DateOffset(months=2)\n",
    "\n",
    "dataset = LargeDatasetSegmentLoader(station_ids, segment_duration)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Example training loop\n",
    "for epoch in range(200):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for combined_features, targets in dataloader:\n",
    "        print(combined_features.shape)\n",
    "        combined_features=combined_features.numpy()\n",
    "        targets=targets.numpy()\n",
    "        combined_features=vectorized_to_float_with_nan(combined_features)\n",
    "        targets=vectorized_to_float_with_nan(targets)\n",
    "        combined_features=torch.tensor(combined_features,dtype=torch.float32)\n",
    "        targets=torch.tensor(targets,dtype=torch.float32)\n",
    "        combined_features, targets = combined_features.to(device), targets.to(device)\n",
    "        x_num=combined_features[:,:20].unsqueeze(1)\n",
    "        x_img=combined_features[:,20:]\n",
    "        x_img=x_img.view(-1,3,224,224)\n",
    "        #force any non numeric values to be numeric\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_num, x_img)\n",
    "        loss = criterion(outputs, targets)\n",
    "        if torch.isnan(loss):\n",
    "            print(\"NaN loss detected\")\n",
    "            print(\"Inputs: \", combined_features)\n",
    "            print(\"Outputs: \", outputs)\n",
    "            print(\"Targets: \", targets)\n",
    "            break\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss/len(dataloader)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define the multimodal neural network\n",
    "class MultimodalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultimodalNet, self).__init__()\n",
    "        \n",
    "        # Define GRU for numerical features\n",
    "        self.gru_num = nn.GRU(20, 64, 1, batch_first=True)\n",
    "        \n",
    "        # Load pre-trained MobileNetV3 as feature extractor\n",
    "        mobilenet = models.mobilenet_v3_small(pretrained=True)\n",
    "        self.mobilenet_features = mobilenet.features\n",
    "        self.mobilenet_classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(576, 128)\n",
    "        )  # Change to output 128-dim features\n",
    "        \n",
    "        # Define linear layers for numerical features\n",
    "        self.fc1_num = nn.Linear(64, 128)\n",
    "        self.fc2_num = nn.Linear(128, 64)\n",
    "        \n",
    "        # Define linear layers for combined features\n",
    "        self.fc1_combined = nn.Linear(192, 64)\n",
    "        self.fc2_combined = nn.Linear(64, 18)  # Output size (18 for regression)\n",
    "\n",
    "    def forward(self, x_num, x_img):\n",
    "        # Extract features using GRU for numerical features\n",
    "        x_num, _ = self.gru_num(x_num)\n",
    "        x_num = x_num[:, -1, :]  # Only take the last hidden state\n",
    "        \n",
    "        # Extract features using MobileNetV3 for image features\n",
    "        x_img = self.mobilenet_features(x_img)\n",
    "        x_img = self.mobilenet_classifier(x_img)\n",
    "        \n",
    "        # Apply linear layers for numerical features\n",
    "        x_num = torch.relu(self.fc1_num(x_num))\n",
    "        x_num = torch.relu(self.fc2_num(x_num))\n",
    "        \n",
    "        # Apply linear layers for combined features\n",
    "        x_combined = torch.cat((x_num, x_img), dim=1)\n",
    "        x_combined = torch.relu(self.fc1_combined(x_combined))\n",
    "        x_combined = self.fc2_combined(x_combined)\n",
    "        \n",
    "        return x_combined\n",
    "\n",
    "# Instantiate and train the model\n",
    "model = MultimodalNet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.gru_num.parameters()},  # GRU parameters\n",
    "    {'params': model.mobilenet_features.parameters(), 'lr': 0.0001},  # MobileNetV3 feature extractor parameters with a lower learning rate\n",
    "    {'params': model.mobilenet_classifier.parameters(), 'lr': 0.0001},  # MobileNetV3 classifier parameters with a lower learning rate\n",
    "    {'params': model.fc1_num.parameters()},\n",
    "    {'params': model.fc2_num.parameters()},\n",
    "    {'params': model.fc1_combined.parameters()},\n",
    "    {'params': model.fc2_combined.parameters()}\n",
    "], lr=0.001)  # Default learning rate for other parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "# Parameters\n",
    "station_ids = ['Keelung','Tucheng','Banqiao','Chiayi']\n",
    "segment_duration = pd.DateOffset(months=2)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = LargeDatasetSegmentLoader(station_ids, segment_duration)\n",
    "dataloader = DataLoader(dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float_with_nan(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return -1\n",
    "\n",
    "vectorized_to_float_with_nan = np.vectorize(to_float_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "for epoch in range(20):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for combined_features,targets in dataloader:\n",
    "        # these combined_features and targets need to be processed\n",
    "        combined_features = vectorized_to_float_with_nan(combined_features).astype(np.float32)\n",
    "        targets = vectorized_to_float_with_nan(targets).astype(np.float32)\n",
    "        # Replace NaNs in combined_features with column means\n",
    "        print(\"Replacing NaNs in combined_features with column means...\")\n",
    "        col_mean_combined = np.nanmean(combined_features, axis=0)\n",
    "        inds_combined = np.where(np.isnan(combined_features))\n",
    "        combined_features[inds_combined] = np.take(col_mean_combined, inds_combined[1])\n",
    "        # Replace NaNs in targets with column means\n",
    "        print(\"Replacing NaNs in targets with column means...\")\n",
    "        col_mean_targets = np.nanmean(targets, axis=0)\n",
    "        inds_targets = np.where(np.isnan(targets))\n",
    "        targets[inds_targets] = np.take(col_mean_targets, inds_targets[1])\n",
    "        # Normalize the first 20 features\n",
    "        scaler=StandardScaler()\n",
    "        combined_features[:,:20]=scaler.fit_transform(combined_features[:,:20])\n",
    "        # Convert to PyTorch tensors\n",
    "        combined_features = torch.tensor(combined_features, dtype=torch.float32)\n",
    "        targets = torch.tensor(targets, dtype=torch.float32)\n",
    "        # Extract numerical and image features\n",
    "        num_features = combined_features[:, :20]  # First 20 columns are numerical features\n",
    "        num_features = num_features.unsqueeze(1)  # Add an extra dimension for GRU\n",
    "        img_features = combined_features[:, 20:]  # Remaining columns are image features\n",
    "\n",
    "        # Reshape image features to (batch_size, 3, 224, 224)\n",
    "        img_features = img_features.reshape(-1, 3, 224, 224)\n",
    "        #set some of the columns of every row to -1 to simulate missing data\n",
    "        mask = torch.rand_like(num_features) < 0.1\n",
    "        num_features[mask] = -1\n",
    "        # move them to gpu\n",
    "        num_features, img_features, targets = num_features.to(device), img_features.to(device), targets.to(device)\n",
    "        # Set some of the values in num_inputs to -1 with a probability of 0.1\n",
    "        optimizer.zero_grad()\n",
    "        # outputs = model(num_inputs.unsqueeze(1), img_inputs)\n",
    "        outputs = model(num_features, img_features)\n",
    "        loss = criterion(outputs, targets)\n",
    "        # if torch.isnan(loss):\n",
    "        #     print(\"NaN loss detected\")\n",
    "        #     print(\"Numerical Inputs: \", num_inputs)\n",
    "        #     print(\"Image Inputs: \", img_inputs)\n",
    "        #     print(\"Outputs: \", outputs)\n",
    "        #     print(\"Targets: \", targets_)\n",
    "        #     break\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch {epoch+1}, Loss: {running_loss}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teep_test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
