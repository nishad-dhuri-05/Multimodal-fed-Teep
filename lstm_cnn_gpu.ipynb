{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_24068\\3248041937.py:52: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  numerical_data['value'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "About to get sample from dataloader...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Custom dataset class\n",
    "class TimeSeriesImageDataset(Dataset):\n",
    "    def __init__(self, numerical_data, image_dir, seq_length=24, transform=None):\n",
    "        self.numerical_data = numerical_data\n",
    "        self.image_dir = image_dir\n",
    "        self.seq_length = seq_length\n",
    "        self.transform = transform\n",
    "        self.scaler = StandardScaler()\n",
    "        self.numerical_data.iloc[:, 2:] = self.scaler.fit_transform(self.numerical_data.iloc[:, 2:])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.numerical_data) - self.seq_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        num_seq = self.numerical_data.iloc[idx:idx + self.seq_length, 2:].values.astype(np.float32)\n",
    "        date_hour_seq = self.numerical_data.iloc[idx:idx + self.seq_length, :2]\n",
    "        images = []\n",
    "\n",
    "        for _, row in date_hour_seq.iterrows():\n",
    "            date_str = row['date'].strftime('%Y%m%d')\n",
    "            hour = row['hour']\n",
    "            image_path = os.path.join(self.image_dir, date_str, f\"{hour}.jpg\")\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            images.append(image)\n",
    "        \n",
    "        images = torch.stack(images)\n",
    "        target = self.numerical_data.iloc[idx + self.seq_length, 2:].values.astype(np.float32)\n",
    "        return {'numerical': torch.tensor(num_seq), 'images': images, 'target': torch.tensor(target)}\n",
    "\n",
    "# Load numerical data\n",
    "numerical_data = pd.read_csv('./dataset/Linkou_2022.csv')\n",
    "numerical_data = numerical_data.drop(columns=['Station'])\n",
    "numerical_data['date'] = pd.to_datetime(numerical_data['date'],format=\"%d-%m-%Y %H:%M\",dayfirst=True)\n",
    "\n",
    "# Melt the data frame to have hours as a column\n",
    "numerical_data = numerical_data.melt(id_vars=['date', 'measurement'], var_name='hour', value_name='value')\n",
    "numerical_data['hour'] = numerical_data['hour'].astype(int)\n",
    "\n",
    "# Check for non-numeric values in 'value' column and convert to numeric\n",
    "numerical_data['value'] = pd.to_numeric(numerical_data['value'], errors='coerce')\n",
    "numerical_data['value'].fillna(0, inplace=True)\n",
    "\n",
    "# Pivot the table\n",
    "numerical_data = numerical_data.pivot_table(index=['date', 'hour'], columns='measurement', values='value').reset_index()\n",
    "\n",
    "# Transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "image_dir = './dataset/009_Linkou'\n",
    "seq_length = 24\n",
    "\n",
    "dataset = TimeSeriesImageDataset(numerical_data, image_dir, seq_length, transform)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "print(\"About to get sample from dataloader...\")\n",
    "# Print a sample for verification\n",
    "sample = next(iter(dataloader))\n",
    "print(sample['numerical'].shape, sample['images'].shape, sample['target'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, cnn_output_size, lstm_hidden_size, seq_length, num_features, num_classes):\n",
    "        super(MultiModalModel, self).__init__()\n",
    "        self.cnn = models.resnet18(pretrained=True)\n",
    "        self.cnn.fc = nn.Linear(self.cnn.fc.in_features, cnn_output_size)\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=num_features, hidden_size=lstm_hidden_size, num_layers=1, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(cnn_output_size + lstm_hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, numerical_data, images):\n",
    "        # Process images through CNN\n",
    "        batch_size, seq_length, c, h, w = images.size()\n",
    "        cnn_output = []\n",
    "        for t in range(seq_length):\n",
    "            out = self.cnn(images[:, t])\n",
    "            cnn_output.append(out)\n",
    "        \n",
    "        cnn_output = torch.stack(cnn_output, dim=1)\n",
    "\n",
    "        # Process numerical data through LSTM\n",
    "        lstm_output, _ = self.lstm(numerical_data)\n",
    "\n",
    "        # Take the last output of the LSTM\n",
    "        lstm_output = lstm_output[:, -1, :]\n",
    "\n",
    "        # Combine outputs\n",
    "        combined_output = torch.cat((cnn_output[:, -1, :], lstm_output), dim=1)\n",
    "\n",
    "        # Fully connected layer\n",
    "        output = self.fc(combined_output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Parameters\n",
    "cnn_output_size = 512\n",
    "lstm_hidden_size = 128\n",
    "seq_length = 24\n",
    "num_features = numerical_data.shape[1] - 2  # exclude 'date' and 'hour'\n",
    "num_classes = num_features  # predicting all features for the next time step\n",
    "\n",
    "# Instantiate model\n",
    "model = MultiModalModel(cnn_output_size, lstm_hidden_size, seq_length, num_features, num_classes)\n",
    "model = model.cuda()  # Move model to GPU\n",
    "\n",
    "# Print model summary for verification\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        numerical_data = batch['numerical'].cuda()\n",
    "        images = batch['images'].cuda()\n",
    "        targets = batch['target'].cuda()\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(numerical_data, images)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "teep_test1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
